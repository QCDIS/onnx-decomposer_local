# onnx-decomposer_local

If needed, perform the preliminary steps first: [README_preliminaries.md](README_preliminaries.md)

## Init Configuration

If not already done, configure the following files as needed:
- `general_config.ini`
- `projects/<projectname>/<projectname>_config.ini`
- `projects/<projectname>/<projectname>_steps.py`

To be safe, it is recommended to use a Python Virtual Environment (venv): `python3 -m venv venv`        
You can activate the virtual environment with `source venv/bin/activate`            
You can deactivate the virtual environment with `deactivate`

From the `root` of the project (`onnx-decomposer_local` folder), run the following commands:        
Install the requirements:
```bash
pip install -r requirements.txt
```

Configure the Python path:
```bash
export PYTHONPATH=$PYTHONPATH:"$PWD":"$PWD/src"
```

## Decomposition and inference

Configure the file `general_config.ini` with the project name and the desired number of slices for the decomposition.

Move to the source folder:
```bash
cd src
```

There are multiple modes to perform different actions:
- `basic` mode: Performs a decomposition in slices, and runs an inference.
- `decomposition` mode: Only performs a decomposition in slices.
- `inference` mode: Only runs an inference (it is required to perform a decomposition beforehand). 

To perform an action, run the following command with the desired mode as argument:
```bash
python3 main.py <mode>
```

## Conformity checks
```bash
# TODO talk about package size here or not?
```
There is a mode to perform each conformity check:
- `payload_per_layer` mode: Analyze payload size per layer. Prints the size of the payload generated by each layer.
- `payload_per_slice` mode: Check payload size violation. Prints the size of the virtual payload generated by each
slice.
- `max_slice_size` mode: Check temporary storage size violation. Prints the size of the heaviest slice.
- `memory` mode: Check memory limit violation. Prints the memory usage for the inference.

To perform a conformity check, run the following command with the desired mode as argument:
```bash
python3 main.py <mode>
```

## AWS-related steps

To go through these steps, you will need a functional AWS account. 
For simple workloads and models, a free tier account is sufficient.         

At the end of the execution, ONNX slices are uploaded to AWS S3 (AWS Cloud Storage).            
For this step to complete, you have to create an S3 bucket.        
Once the S3 bucket is created, configure the file `<projectname>_config.ini` with your AWS region
and the name of the S3 bucket.

## References

This project includes code and content from the following sources:
- [tensorflow-onnx](https://github.com/onnx/tensorflow-onnx/)
```bash
# TODO add other references
```
